{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5wpNIeA3sbC",
        "outputId": "645e0838-bae3-4883-cdac-80f24e6b9929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category-encoders in /usr/local/lib/python3.10/dist-packages (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (0.14.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (0.5.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category-encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category-encoders) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category-encoders) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category-encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category-encoders) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category-encoders) (24.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install category-encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "33OCg_IUZrGH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler ,StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from category_encoders import HashingEncoder\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbdkjebZHn3K",
        "outputId": "d6dec1b0-f5c7-4d35-f72a-953815f60dd4"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'ApartmentRentPrediction.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ab3567be8721>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ApartmentRentPrediction.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"price_display\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ApartmentRentPrediction.csv'"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "data = pd.read_csv(\"ApartmentRentPrediction.csv\")\n",
        "data[\"price_display\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91Bko8lWjwRV"
      },
      "source": [
        "droping nulls from Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yFUsCjjMPcv6"
      },
      "outputs": [],
      "source": [
        "#nully = proj[\"price_display\"].isnull()\n",
        "#proj = proj[~nully]\n",
        "data = data.dropna(subset=[\"price_display\"])\n",
        "proj = data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Z8gdchj_H_"
      },
      "source": [
        "index 12 is the target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dz9CLka0PWOi"
      },
      "outputs": [],
      "source": [
        "x = proj.iloc[:, list(range(0, 11)) + list(range(13, 22))]\n",
        "x['time'] = pd.to_datetime(x['time']).dt.time\n",
        "y = proj[\"price_display\"].str.replace(r'\\D+','', regex=True).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E_cHW_G_3o0t"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pBR1Qjri_XJs"
      },
      "outputs": [],
      "source": [
        "def extract_beds(text):\n",
        "    matches_numeric = re.findall(r'(\\d+) beds?', text, re.IGNORECASE)  # Ignorecase for makig beds not case sensitive\n",
        "    if matches_numeric:\n",
        "        return int(matches_numeric[0])\n",
        "\n",
        "\n",
        "    number_words = {'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10}\n",
        "    for word, number in number_words.items():\n",
        "        if word in text.lower():\n",
        "            return number\n",
        "\n",
        "    return None\n",
        "x['beds'] = x['body'].apply(extract_beds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8u0_8XQFZ6dQ"
      },
      "outputs": [],
      "source": [
        "x.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y1Sg26DrPi8_"
      },
      "outputs": [],
      "source": [
        "y.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YtAFZUvp-vzj"
      },
      "outputs": [],
      "source": [
        "x_train.drop(columns=[\"time\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k9nSMOs3x7ir"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "def replace_nulls(df, type='test', X_trainApply=x_train):\n",
        "  if type == 'train':\n",
        "    numeric_columns = df.select_dtypes(include=['number']).columns\n",
        "    string_columns = df.select_dtypes(exclude=['number']).columns\n",
        "    for ncol in numeric_columns:\n",
        "        df[ncol] = df[ncol].fillna(df[ncol].mean())\n",
        "    for scol in string_columns:\n",
        "      df[scol] = df[scol].fillna(df[scol].mode()[0])\n",
        "  else :\n",
        "    numeric_columns = df.select_dtypes(include=['number']).columns\n",
        "    string_columns = df.select_dtypes(exclude=['number']).columns\n",
        "    for ncol in numeric_columns:\n",
        "        df[ncol] = df[ncol].fillna(X_trainApply[ncol].mean())\n",
        "    for scol in string_columns:\n",
        "      df[scol] = df[scol].fillna(X_trainApply[scol].mode()[0])\n",
        "\n",
        "replace_nulls(x_train, 'train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cfBhDn5uDnax"
      },
      "outputs": [],
      "source": [
        "def outlier_detection(df):\n",
        "  if x is not None:\n",
        "    numeric_columns = df.select_dtypes(include=['number']).columns\n",
        "    for col in numeric_columns:\n",
        "      Q1 = df[col].quantile(0.25)\n",
        "      Q3 = df[col].quantile(0.75)\n",
        "      IQR = Q3 - Q1\n",
        "      outliers =(df[col] < (Q1 - 1.5 * IQR)) | (df[col] >( Q3 + 1.5 * IQR))\n",
        "      print(f\"{col}: {outliers.sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aZiRK_z3DtMT"
      },
      "outputs": [],
      "source": [
        "outlier_detection(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5-uqmGvYo-hv"
      },
      "outputs": [],
      "source": [
        "def replace_outliers(df):\n",
        "  numeric_columns = df.select_dtypes(include=['number']).columns\n",
        "  for col in numeric_columns:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    df[col] = np.where((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR)), Q3 , df[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Xab1UmQrVQO"
      },
      "outputs": [],
      "source": [
        "#replace_outliers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C9unu5bmQxwg"
      },
      "outputs": [],
      "source": [
        "x.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_nFtStASrnpJ"
      },
      "outputs": [],
      "source": [
        "columns = ['cityname','amenities' , 'address']\n",
        "target_encoder = ce.TargetEncoder()\n",
        "for col in columns:\n",
        "  x_encoded = target_encoder.fit_transform(x[col], y)\n",
        "  x[col] = x_encoded[col]\n",
        "\n",
        "with open(\"target_encoder.pkl\", \"wb\") as file:\n",
        "    pickle.dump(target_encoder, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "psQBdszpd2ey"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iB40DzXGpd97"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "cols=['pets_allowed', 'price_type','fee','currency','has_photo','amenities', 'address', 'body', 'category', 'cityname', 'state', 'source', 'title']\n",
        "label_encoders = {}\n",
        "\n",
        "for col in cols:\n",
        "    label_encoder = LabelEncoder()\n",
        "    x_train[col] = label_encoder.fit_transform(x_train[col])\n",
        "    label_encoders[col] = label_encoder\n",
        "\n",
        "with open('label_encoders.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoders, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HzQWrCVGwdmj"
      },
      "outputs": [],
      "source": [
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jo7C2hmBUnNe"
      },
      "outputs": [],
      "source": [
        "x_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4QVhyXz1zGa2"
      },
      "outputs": [],
      "source": [
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mOOLedEiLzjj"
      },
      "outputs": [],
      "source": [
        "x.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VmqkaLky1AGc"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.drop(['id','currency' , 'fee'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cbx_H6m4INIH"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "x_train[x_train.columns] = scaler.fit_transform(x_train[x_train.columns])\n",
        "with open(\"scaler.pkl\", \"wb\") as file:\n",
        "    pickle.dump(scaler, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DcAa1FU_KFzt"
      },
      "outputs": [],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W3O20m_M18qa"
      },
      "outputs": [],
      "source": [
        "def correlation(x, y):\n",
        "  df = pd.concat([x, y], axis=1)\n",
        "  corr = df.corr()\n",
        "  top_feature = corr.index[abs(corr['price_display'])>0.2]\n",
        "\n",
        "  plt.figure(figsize=(16, 14))\n",
        "  sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".4f\")\n",
        "  plt.show()\n",
        "  top_feature = top_feature.delete(-1)\n",
        "  return x[top_feature]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j1GtrTT6GXry"
      },
      "outputs": [],
      "source": [
        "X_train = x_train\n",
        "x_train = correlation(x_train, y_train)\n",
        "with open(\"correlation_function.pkl\", \"wb\") as file:\n",
        "    pickle.dump(correlation, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jgcAMxDf3_gh"
      },
      "outputs": [],
      "source": [
        "x_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bff8Cpfk3Rti"
      },
      "outputs": [],
      "source": [
        "# Define the regression models\n",
        "models = [\n",
        "    ('Linear Regression', LinearRegression()),\n",
        "    ('Ridge Regression', RidgeCV()),\n",
        "    ('Lasso Regression', LassoCV()),\n",
        "    ('Polynomial Regression', PolynomialFeatures(degree=2)),\n",
        "    ('Random Forest', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
        "    ('Decision Tree', DecisionTreeRegressor())\n",
        "]\n",
        "\n",
        "\n",
        "# Iterate over each model\n",
        "for name, model in models:\n",
        "    # Check if the current model is Polynomial Regression, Random Forest, or Decision Tree\n",
        "    if name in ['Polynomial Regression', 'Random Forest', 'Decision Tree']:\n",
        "        # For Polynomial Regression, create polynomial features and use Linear Regression\n",
        "        if name == 'Polynomial Regression':\n",
        "            poly = PolynomialFeatures(degree=2)\n",
        "            x_poly = poly.fit_transform(x_train)\n",
        "            model = LinearRegression()\n",
        "        # For Random Forest, use RandomForestRegressor\n",
        "        elif name == 'Random Forest':\n",
        "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        # For Decision Tree, use DecisionTreeRegressor\n",
        "        else:\n",
        "            model = DecisionTreeRegressor()\n",
        "\n",
        "    #     # Perform Recursive Feature Elimination with Cross-Validation (RFECV)\n",
        "    #     rfecv = RFECV(estimator=model, step=1, cv=5, scoring='neg_mean_squared_error')\n",
        "    #     rfecv.fit(x_train, y_train)\n",
        "    #     x_selected = x_train.iloc[:, rfecv.support_]\n",
        "    # else:\n",
        "    #     # For other models, perform RFECV without modifying the model\n",
        "    #     rfecv = RFECV(estimator=model, step=1, cv=5, scoring='neg_mean_squared_error')\n",
        "    #     rfecv.fit(x_train, y_train)\n",
        "    #     x_selected = x_train.iloc[:, rfecv.support_]\n",
        "\n",
        "    # Fit the model on the selected features\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_train)\n",
        "    mse = ((y_train - y_pred) ** 2).mean()\n",
        "\n",
        "    r2 = r2_score(y_train, y_pred)\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    model.fit(x_train, y_train)\n",
        "    with open(f\"{name}_trained_model.pkl\", \"wb\") as file:\n",
        "      pickle.dump(model, file)\n",
        "    y_pred_train = model.predict(x_train)\n",
        "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "    r2_train = r2_score(y_train, y_pred_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql8Jh6YOyk4X"
      },
      "source": [
        "apply random forest because it's more accurate from linear regression because the data non-linear (the corelation with target not close to (1,-1))\n",
        "\n",
        "and more effecient than decision tree because that work with multiple trees and that will reduce the overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a5MtW-02YxA"
      },
      "source": [
        "apply feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "Gsuw-t6l8EOa"
      },
      "outputs": [],
      "source": [
        "new_data = pd.read_csv(\"/content/ApartmentRentPrediction_test.csv\")\n",
        "new_data = new_data.dropna(subset=[\"price_display\"])\n",
        "\n",
        "model_names = ['Linear Regression', 'Ridge Regression', 'Lasso Regression',\n",
        "               'Polynomial Regression', 'Random Forest', 'Decision Tree']\n",
        "\n",
        "new_data_features = pd.DataFrame(new_data.loc[:, ~new_data.columns.isin([\"price_display\",\"price\", \"time\",\"id\",\"currency\" , \"fee\"])])\n",
        "new_data_target = new_data[\"price_display\"]\n",
        "replace_nulls(new_data_features)\n",
        "\n",
        "with open(\"target_encoder.pkl\", \"rb\") as file:\n",
        "    loaded_target_encoder = pickle.load(file)\n",
        "\n",
        "columns = ['cityname', 'amenities', 'Address']\n",
        "missing_columns = [col for col in columns if col not in new_data.columns]\n",
        "if not missing_columns:\n",
        "    for col in columns:\n",
        "        new_data[col] = loaded_target_encoder.transform(new_data[col])\n",
        "\n",
        "labelencoders = pickle.load(open('label_encoders.pkl', 'rb'))\n",
        "\n",
        "cols=['pets_allowed', 'price_type','has_photo','amenities', 'address', 'body', 'category', 'cityname', 'state', 'source', 'title']\n",
        "for col in cols:\n",
        "    new_data_features[col] = new_data_features[col].apply(lambda s: labelencoders[col].transform([s])[0] if s in labelencoders[col].classes_ else s)\n",
        "\n",
        "\n",
        "for col in cols:\n",
        "  max_value_train = X_train[col].max()\n",
        "  unique_values_test = new_data_features[col].unique()\n",
        "  for value in unique_values_test:\n",
        "    if value not in X_train[col].unique():\n",
        "      max_value_train += 1\n",
        "      new_data_features.loc[new_data[col] == value, col] = max_value_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bQXPwN0qBsPw"
      },
      "outputs": [],
      "source": [
        "with open(\"scaler.pkl\", \"rb\") as file:\n",
        "    loaded_scaler = pickle.load(file)\n",
        "\n",
        "columns_to_scale = X_train.columns\n",
        "new_data_features[columns_to_scale] = loaded_scaler.transform(new_data_features[columns_to_scale])\n",
        "new_data_target = pd.DataFrame(new_data_target)\n",
        "new_data_target = new_data_target[\"price_display\"].str.replace(r'\\D+','', regex=True).astype(int)\n",
        "\n",
        "with open(\"correlation_function.pkl\", \"rb\") as file:\n",
        "    loaded_correlation = pickle.load(file)\n",
        "new_data_features = loaded_correlation(new_data_features,new_data_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WjGwW0CM5iCU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "new_data_features = pd.DataFrame(new_data.loc[:, ~new_data.columns.isin([\"RentCategory\", \"time\"])])\n",
        "for name in ['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Polynomial Regression', 'Random Forest', 'Decision Tree']:\n",
        "    # Load the trained model from the pickle file\n",
        "    model_filename = f\"{name}_trained_model.pkl\"\n",
        "    with open(model_filename, \"rb\") as file:\n",
        "        model = pickle.load(file)\n",
        "\n",
        "    # Make predictions on the new data using the loaded model\n",
        "    y_pred_new = model.predict(new_data_features)\n",
        "\n",
        "    # Compute regression metrics\n",
        "    mse = mean_squared_error(new_data_target, y_pred_new)\n",
        "    mae = mean_absolute_error(new_data_target, y_pred_new)\n",
        "    r2 = r2_score(new_data_target, y_pred_new)\n",
        "\n",
        "    # Print the regression metrics\n",
        "    print(f\"Regression Metrics for {name}:\")\n",
        "    print(\"Mean Squared Error:\", mse)\n",
        "    print(\"Mean Absolute Error:\", mae)\n",
        "    print(\"R-squared Score:\", r2)\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}